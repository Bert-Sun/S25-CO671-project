% This template has been tested with LLNCS DOCUMENT CLASS -- version 2.21 (12-Jan-2022)

% !TeX spellcheck = en-US
% LTeX: language=en-US
% !TeX encoding = utf8
% !TeX program = lualatex
% !BIB program = bibtex
% -*- coding:utf-8 mod:LaTeX -*-

% "a4paper" enables:
%
%  - easy print out on DIN A4 paper size
%
% One can configure default page size (a4 vs. letter) in the LaTeX installation.
% Thus, it is configuration dependend, what the paper size will be.
% Having "a4paper" option present, the page size is set to A4.
% Note that the current word template offered by Springer is DIN A4.
%
% "runningheads" enables:
%
%  - page number on page 2 onwards
%  - title/authors on even/odd pages
%
% This is good for other readers to enable proper archiving among other papers and pointing to
% content. Even if the title page states the title, when printed and stored in a folder, when
% blindly opening the folder, one could hit not the title page, but an arbitrary page. Therefore,
% it is good to have title printed on the pages, too.
%
% The optiion "runningheads" neesd to be removed upon request of the publisher.
%
% To disable outputting page headers and footers, remove "runningheads"
\documentclass[runningheads,a4paper,english]{llncs}[2022/01/12]

\usepackage{amsmath, amssymb, mathtools, mathrsfs}

\usepackage{iftex}

% backticks (`) are rendered as such in verbatim environments.
% See following links for details:
%   - https://tex.stackexchange.com/a/341057/9075
%   - https://tex.stackexchange.com/a/47451/9075
%   - https://tex.stackexchange.com/a/166791/9075
\usepackage{upquote}

% Set English as language and allow to write hyphenated"=words
%
% Even though `american`, `english` and `USenglish` are synonyms for babel package (according to https://tex.stackexchange.com/questions/12775/babel-english-american-usenglish), the llncs document class is prepared to avoid the overriding of certain names (such as "Abstract." -> "Abstract" or "Fig." -> "Figure") when using `english`, but not when using the other 2.
% english has to go last to set it as default language
\usepackage[ngerman,main=english]{babel}
%
% Hint by http://tex.stackexchange.com/a/321066/9075 -> enable "= as dashes
\addto\extrasenglish{\languageshorthands{ngerman}\useshorthands{"}}

% Links behave as they should. Enables "\url{...}" for URL typesettings.
% Allow URL breaks also at a hyphen, even though it might be confusing: Is the "-" part of the address or just a hyphen?
% See https://tex.stackexchange.com/a/3034/9075.
\usepackage[hyphens]{url}

% When activated, use text font as url font, not the monospaced one.
% For all options see https://tex.stackexchange.com/a/261435/9075.
% \urlstyle{same}

% Improve wrapping of URLs - hint by http://tex.stackexchange.com/a/10419/9075
\makeatletter
\g@addto@macro{\UrlBreaks}{\UrlOrds}
\makeatother

% nicer // - solution by http://tex.stackexchange.com/a/98470/9075
% DO NOT ACTIVATE -> prevents line breaks
%\makeatletter
%\def\Url@twoslashes{\mathchar`\/\@ifnextchar/{\kern-.2em}{}}
%\g@addto@macro\UrlSpecials{\do\/{\Url@twoslashes}}
%\makeatother

%% !!! If you change the font, be sure that words such as "workflow" can
%% !!! still be copied from the PDF. If this is not the case, you have
%% !!! to use glyphtounicode. See comment at cmap package.
%%
%% Background: "workflow" contains "fl" which is a ligature, which in turn
%%             is rendered as one character in the PDF and needs to be split
%%             whily copying.

\ifluatex
  \usepackage[no-math]{fontspec}
  \usepackage{unicode-math}

  % Typewriter font (for source code etc)
  % Use New Computer Modern font (Computer Modern is the default LaTeX font; this is the implemented modern variant)
  % Source: https://tug.org/FontCatalogue/newcomputermoderntypewriter/

  \setmainfont[
    ItalicFont=NewCM10-Italic.otf,
    BoldFont=NewCM10-Bold.otf,
    BoldItalicFont=NewCM10-BoldItalic.otf,
    SmallCapsFeatures={Numbers=OldStyle}]{NewCM10-Regular.otf}

  \setsansfont[
    ItalicFont=NewCMSans10-Oblique.otf,
    BoldFont=NewCMSans10-Bold.otf,
    BoldItalicFont=NewCMSans10-BoldOblique.otf,
    SmallCapsFeatures={Numbers=OldStyle}]{NewCMSans10-Regular.otf}

  \setmonofont[ItalicFont=NewCMMono10-Italic.otf,
    BoldFont=NewCMMono10-Bold.otf,
    BoldItalicFont=NewCMMono10-BoldOblique.otf,
    SmallCapsFeatures={Numbers=OldStyle}]{NewCMMono10-Regular.otf}

  \setmathfont{NewCMMath-Regular.otf}

  % Enable proper ligatures
  % For more information see https://ctan.org/pkg/selnolig
  % language "english" or "ngerman" is passed to selnolig by the document class
  \usepackage{selnolig}

\else
  % This is the modern package for "Computer Modern".
  % In case this gets activated, one has to switch from cmap package to glyphtounicode (in the case of pdflatex)
  \usepackage[%
    rm={oldstyle=false,proportional=true},%
    sf={oldstyle=false,proportional=true},%
    % By using 'variable=true' the monospaced font can be used as variable font (with differents widths per letter)
    % However, this makes listings look ugly.
    tt={oldstyle=false,proportional=true,variable=false},%
    qt=false%
  ]{cfr-lm}

  % Has to be loaded AFTER any font packages. See https://tex.stackexchange.com/a/2869/9075.
  \usepackage[T1]{fontenc}
\fi

% Character protrusion and font expansion. See http://www.ctan.org/tex-archive/macros/latex/contrib/microtype/

\usepackage[
  babel=true, % Enable language-specific kerning. Take language-settings from the languge of the current document (see Section 6 of microtype.pdf)
  expansion=alltext,
  protrusion=alltext-nott, % Ensure that at listings, there is no change at the margin of the listing
  % In the standard configuration, this template is always in the final mode, so this option only makes a difference if "pros" use the draft mode
  final % Always enable microtype, even if in draft mode. This helps finding bad boxes quickly.
]{microtype}

% \texttt{test -- test} keeps the "--" as "--" (and does not convert it to an en dash)
\DisableLigatures{encoding = T1, family = tt* }

%\DeclareMicrotypeSet*[tracking]{my}{ font = */*/*/sc/* }%
%\SetTracking{ encoding = *, shape = sc }{ 45 }
% Source: http://homepage.ruhr-uni-bochum.de/Georg.Verweyen/pakete.html
% Deactiviated, because does not look good

\usepackage{graphicx}

% Diagonal lines in a table - http://tex.stackexchange.com/questions/17745/diagonal-lines-in-table-cell
% Slashbox is not available in texlive (due to licensing) and also gives bad results. Thus, we use diagbox
\usepackage{diagbox}

\ifluatex
  \usepackage{spelling}
  \spellingoutput{off}
\fi

\usepackage[dvipsnames, table]{xcolor}
% Code Listings
\usepackage{listings}

\definecolor{eclipseStrings}{RGB}{42,0.0,255}
\definecolor{eclipseKeywords}{RGB}{127,0,85}
\colorlet{numb}{magenta!60!black}

% JSON definition
% Source: https://tex.stackexchange.com/a/433961/9075

\lstdefinelanguage{json}{
  basicstyle=\normalfont\ttfamily,
  commentstyle=\color{eclipseStrings}, % style of comment
  stringstyle=\color{eclipseKeywords}, % style of strings
  numbers=left,
  numberstyle=\scriptsize,
  stepnumber=1,
  numbersep=8pt,
  showstringspaces=false,
  breaklines=true,
  frame=lines,
  % backgroundcolor=\color{gray}, %only if you like
  string=[s]{"}{"},
  comment=[l]{:\ "},
  morecomment=[l]{:"},
  literate=
    *{0}{{{\color{numb}0}}}{1}
    {1}{{{\color{numb}1}}}{1}
    {2}{{{\color{numb}2}}}{1}
    {3}{{{\color{numb}3}}}{1}
    {4}{{{\color{numb}4}}}{1}
    {5}{{{\color{numb}5}}}{1}
    {6}{{{\color{numb}6}}}{1}
    {7}{{{\color{numb}7}}}{1}
    {8}{{{\color{numb}8}}}{1}
    {9}{{{\color{numb}9}}}{1}
}

\lstset{
  % everything between (* *) is a latex command
  escapeinside={(*}{*)},
  %
  language=json,
  %
  showstringspaces=false,
  %
  extendedchars=true,
  %
  basicstyle=\footnotesize\ttfamily,
  %
  commentstyle=\slshape,
  %
  % default: \rmfamily
  stringstyle=\ttfamily,
  %
  breaklines=true,            % Zeilen werden umbrochen
  %
  breakatwhitespace=true,
  %
  % alternative: fixed
  columns=flexible,
  %
  tabsize=2,                  % Groesse von Tabs
  %
  numbers=left,
  %
  numberstyle=\tiny,
  %
  basewidth=.5em,
  %
  xleftmargin=.5cm,
  %
  % aboveskip=0mm,
  %
  % belowskip=0mm,
  %
  captionpos=b
}
\ifpdftex

  % Enable Umlauts when using \lstinputputlisting.
  % See https://stackoverflow.com/a/29260603/873282 für details.
  % listingsutf8 did not work in June 2020.
  \lstset{literate=
    {á}{{\'a}}1 {é}{{\'e}}1 {í}{{\'i}}1 {ó}{{\'o}}1 {ú}{{\'u}}1
  {Á}{{\'A}}1 {É}{{\'E}}1 {Í}{{\'I}}1 {Ó}{{\'O}}1 {Ú}{{\'U}}1
  {à}{{\`a}}1 {è}{{\`e}}1 {ì}{{\`i}}1 {ò}{{\`o}}1 {ù}{{\`u}}1
  {À}{{\`A}}1 {È}{{\'E}}1 {Ì}{{\`I}}1 {Ò}{{\`O}}1 {Ù}{{\`U}}1
  {ä}{{\"a}}1 {ë}{{\"e}}1 {ï}{{\"i}}1 {ö}{{\"o}}1 {ü}{{\"u}}1
  {Ä}{{\"A}}1 {Ë}{{\"E}}1 {Ï}{{\"I}}1 {Ö}{{\"O}}1 {Ü}{{\"U}}1
  {â}{{\^a}}1 {ê}{{\^e}}1 {î}{{\^i}}1 {ô}{{\^o}}1 {û}{{\^u}}1
  {Â}{{\^A}}1 {Ê}{{\^E}}1 {Î}{{\^I}}1 {Ô}{{\^O}}1 {Û}{{\^U}}1
  {Ã}{{\~A}}1 {ã}{{\~a}}1 {Õ}{{\~O}}1 {õ}{{\~o}}1
  {œ}{{\oe}}1 {Œ}{{\OE}}1 {æ}{{\ae}}1 {Æ}{{\AE}}1 {ß}{{\ss}}1
  {ű}{{\H{u}}}1 {Ű}{{\H{U}}}1 {ő}{{\H{o}}}1 {Ő}{{\H{O}}}1
  {ç}{{\c c}}1 {Ç}{{\c C}}1 {ø}{{\o}}1 {å}{{\r a}}1 {Å}{{\r A}}1
  }
\fi

\lstloadlanguages{% Check dokumentation for further languages...
  %[Visual]Basic
  %Pascal
  %C
  %C++
  %XML
  %HTML
}

% For easy quotations: \enquote{text}
% This package is very smart when nesting is applied, otherwise textcmds (see below) provides a shorter command
\usepackage[autostyle=true]{csquotes}

% Enable using "`quote"' - see https://tex.stackexchange.com/a/150954/9075
\defineshorthand{"`}{\openautoquote}
\defineshorthand{"'}{\closeautoquote}

% Nicer tables (\toprule, \midrule, \bottomrule)
\usepackage{booktabs}

% Extended enumerate, such as \begin{compactenum}
\usepackage{paralist}

% Bibliopgraphy enhancements
%  - enable \cite[prenote][]{ref}
%  - enable \cite{ref1,ref2}
% Alternative: \usepackage{cite}, which enables \cite{ref1, ref2} only (otherwise: Error message: "White space in argument")

% Doc: http://texdoc.net/natbib
\usepackage[%
  square,        % for square brackets
  comma,         % use commas as separators
  numbers,       % for numerical citations;
  %sort           % orders multiple citations into the sequence in which they appear in the list of references;
  sort&compress  % as sort but in addition multiple numerical citations are compressed if possible (as 3-6, 15);
]{natbib}

% In the bibliography, references have to be formatted as 1., 2., ... not [1], [2], ...
\renewcommand{\bibnumfmt}[1]{#1.}

% Enable hyperlinked author names in the case of \citet
% Source: https://tex.stackexchange.com/a/76075/9075
\usepackage{etoolbox}
\makeatletter
\patchcmd{\NAT@test}{\else \NAT@nm}{\else \NAT@hyper@{\NAT@nm}}{}{}
\makeatother

% Prepare more space-saving rendering of the bibliography
% Source: https://tex.stackexchange.com/a/280936/9075
\SetExpansion
[ context = sloppy,
  stretch = 30,
  shrink = 60,
  step = 5 ]
{ encoding = {OT1,T1,TS1} }
{ }

% Put figures aside a text
% Even though the package is from 1998, it works well
\usepackage[rflt]{floatflt}

% Farbige Tabellen
% ----------------
% Das Paket colortbl wird inzwischen automatisch durch xcolor geladen
%
% Erweiterte Funktionen innerhalb von Tabellen
% --------------------------------------------
%%% Doc: http://mirror.ctan.org/tex-archive/macros/latex/contrib/multirow/multirow.sty
\usepackage{multirow} % Mehrfachspalten
%
%%% Doc: Documentation inside dtx Package
\usepackage{dcolumn}  % Ausrichtung an Komma oder Punkt

%%% Doc: http://mirror.ctan.org/tex-archive/macros/latex/contrib/supertabular/supertabular.pdf
%\usepackage{supertabular}

%%% Fussnoten/Endnoten ===================================================

% EN: Put footnotes below floats
% DE: Fußnoten unter Gleitumgebungen ("floats") platzieren
% Source: https://tex.stackexchange.com/a/32993/9075
\usepackage{stfloats}
\fnbelowfloat

% EN: Extended support for footnotes
% DE: Fußnoten
%
%\usepackage{dblfnote}  %Zweispaltige Fußnoten
%
% Keine hochgestellten Ziffern in der Fußnote (KOMA-Script-spezifisch):
%\deffootnote[1.5em]{0pt}{1em}{\makebox[1.5em][l]{\bfseries\thefootnotemark}}
%
% Abstand zwischen Fußnoten vergrößern:
%\setlength{\footnotesep}{.85\baselineskip}
%
% EN: Following command disables the separting line of the footnote
% DE: Folgendes Kommando deaktiviert die Trennlinie zur Fußnote
%\renewcommand{\footnoterule}{}
%
%\addtolength{\skip\footins}{\baselineskip} % Abstand Text <-> Fußnote

% DE: Fußnoten immer ganz unten auf einer \raggedbottom-Seite
% DE: fnpos kommt aus dem yafoot package
%\usepackage{fnpos}
%\makeFNbelow
%\makeFNbottom

% TODO (and comment) configuration
%
% - \todo (from todo, easy-todo, todonotes) / \TODO (from fixmetodonotes) - for "normal" TODOs
% - \todofix - "important" TODOs
%
% - \textcomment - highlights text and has a hover comment
% - \sidecomment - just puts a comment to the side. Note: \comment MUST NOT be used as command name, it is already defined by much packages (mathdesign, mindflow, verbatim, and others)
%
% - \missingfigure
%
% - \textmarker
% - \modified
% - \change      - adresses a review comment

% Enable nice comments
\usepackage{pdfcomment}

\newcommand{\textcomment}[2]{\colorbox{yellow!60}{#1}\pdfcomment[color={0.234 0.867 0.211},hoffset=-6pt,voffset=10pt,opacity=0.5]{#2}}

% Small PDF comment
% 1. Parameter: Comment
\newcommand{\sidecomment}[1]{\pdfcomment[color={0.045 0.278 0.643},voffset=4pt,icon=Note]{#1}}
% Disabled variant - for the final PDF
%\newcommand{\sidecomment}[1]{}

\newcommand{\todo}[1]{TODO!\sidecomment{#1}}

% Änderungen
%
% 1. Parameter: Review-Kommentar
% 2. Parameter: Neuer Text
\newcommand{\change}[2]{{\color{red}#2}\pdfcomment[color={0.234 0.867 0.211},voffset=8pt,opacity=0.5]{#1}}
% Disabled variant - for the final PDF
%\newcommand{\change}[2]{#2}

% Define default commands
\makeatletter
\@ifundefined{missingfigure}{\newcommand{\missingfigure}{... missing figure ...}}{}
\@ifundefined{textcomment}{\newcommand{\textcomment}[2]{#1 \todo{#2}}}{}
\@ifundefined{sidecomment}{\newcommand{\sidecomment}[1]{\marginpar{#1}}}{}
\@ifundefined{todo}{\newcommand{\todo}[1]{\sidecomment{#1}}}{}
\@ifundefined{TODO}{\newcommand{\TODO}[1]{\todo{#1}}}{}
\@ifundefined{todofix}{\newcommand{\todofix}[1]{\todo{#1}}}{}
\@ifundefined{change}{\newcommand{\change}[2]{#1 $\rightarrow$ #2}}{}
\makeatother

% Textmarker (Textfarbe rot)
\newcommand{\textmarker}[1]{{\color{red} #1}\xspace}

% Modified (Text blau)
\newcommand{\modified}[1]{{\color{blue!60!black} #1}\xspace}

\usepackage[group-minimum-digits=4,per-mode=fraction]{siunitx}

% Enable that parameters of \cref{}, \ref{}, \cite{}, ... are linked so that a reader can click on the number an jump to the target in the document
\usepackage{hyperref}

% Enable hyperref without colors and without bookmarks
\hypersetup{
  hidelinks,
  colorlinks=true,       % Links erhalten Farben statt Kaeten
  raiselinks=true,       % calculate real height of the link
  allcolors=black,
  pdfstartview=Fit,
  breaklinks=true,       % Links ueberstehen Zeilenumbruch
  hypertexnames=false,   % Fix jumping to algorithm line - http://tex.stackexchange.com/a/156404/9075
}

% Enable correct jumping to figures when referencing
\usepackage[all]{hypcap}

\usepackage[caption=false,font=footnotesize]{subfig}

% Alternative for making subfigures:
% Part of the caption package. See http://www.ctan.org/pkg/caption
% Ersetzt die Pakete subfigure und subfig - siehe https://tex.stackexchange.com/a/13778/9075
%
% (subfigure is outdated. subfig is maintained, but subcaption is better)
% See: http://tex.stackexchange.com/questions/13625/subcaption-vs-subfig-best-package-for-referencing-a-subfigure
%\usepackage[hypcap=true]{subcaption}

\usepackage{mindflow}

% Extensions for references inside the document (\cref{fig:sample}, ...)
% Enable usage \cref{...} and \Cref{...} instead of \ref: Type of reference included in the link
% That means, "Figure 5" is a full link instead of just "5".
\usepackage[capitalise,nameinlink]{cleveref}

\crefname{section}{Sect.}{Sect.}
\Crefname{section}{Section}{Sections}
\crefname{listing}{List.}{List.}
\crefname{listing}{Listing}{Listings}
\Crefname{listing}{Listing}{Listings}
\crefname{lstlisting}{Listing}{Listings}
\Crefname{lstlisting}{Listing}{Listings}

\usepackage{lipsum}

% For demonstration purposes only
% These packages can be removed when all examples have been deleted
\usepackage[math]{blindtext}
\usepackage{mwe}
\usepackage[realmainfile]{currfile}
\usepackage{tcolorbox}
\tcbuselibrary{listings}

%introduce \powerset - hint by http://matheplanet.com/matheplanet/nuke/html/viewtopic.php?topic=136492&post_id=997377
\DeclareFontFamily{U}{MnSymbolC}{}
\DeclareSymbolFont{MnSyC}{U}{MnSymbolC}{m}{n}
\DeclareFontShape{U}{MnSymbolC}{m}{n}{
  <-6>    MnSymbolC5
  <6-7>   MnSymbolC6
  <7-8>   MnSymbolC7
  <8-9>   MnSymbolC8
  <9-10>  MnSymbolC9
  <10-12> MnSymbolC10
  <12->   MnSymbolC12%
}{}
\DeclareMathSymbol{\powerset}{\mathord}{MnSyC}{180}

% Allows for defining commands that don't eat spaces.
\usepackage{xspace}
% Adds compatibility to \xspace und \enquote
\makeatletter
\xspaceaddexceptions{\grqq \grq \csq@qclose@i \} }
\makeatother

\newcommand{\eg}{e.g.,\ }
\newcommand{\ie}{i.e.,\ }

% Enable hyphenation at other places as the dash.
% Example: applicaiton\hydash specific
\makeatletter
\newcommand{\hydash}{\penalty\@M-\hskip\z@skip}
% Definition of "= taken from http://mirror.ctan.org/macros/latex/contrib/babel-contrib/german/ngermanb.dtx
\makeatother

% Add manual adapted hyphenation of English words
% See https://ctan.org/pkg/hyphenex and https://tex.stackexchange.com/a/22892/9075 for details
\input{ushyphex}

% correct bad hyphenation here
\hyphenation{
  op-tical net-works semi-conduc-tor
  % May not be hypphenated
  AROMA TOSCA BPMN OASIS OMG DMTF IT DevOps
}
\input{commands}

% Add copyright
%
% This is recommended if you intend to send the version to colleagues
% See https://ctan.org/pkg/llncsconf for details
\iffalse
  % state: intended | submitted | llncs
  % you can add "crop" if the paper should be cropped to the format Springer is publishing
  \usepackage[intended]{llncsconf}

  \conference{name of the conference}

  % in case of "proceedings" (final version!)
  % example: \llncs{Anonymous et al. (eds). \emph{Proceedings of the International Conference on \LaTeX-Hacks}, LNCS~42. Some Publisher, 2016.}{0042}
  % 0042 denotes an example start page
  \llncs{book editors and title}{0042}
\fi

\ifpdftex
  % Enable copy and paste of text from the PDF
  % Only required for pdflatex. It "just works" in the case of lualatex.
  % Alternative: cmap or mmap package
  % mmap enables mathematical symbols, but does not work with the newtx font set
  % See: https://tex.stackexchange.com/a/64457/9075
  % Other solutions outlined at http://goemonx.blogspot.de/2012/01/pdflatex-ligaturen-und-copynpaste.html and http://tex.stackexchange.com/questions/4397/make-ligatures-in-linux-libertine-copyable-and-searchable
  % Trouble shooting outlined at https://tex.stackexchange.com/a/100618/9075
  %
  % According to https://tex.stackexchange.com/q/451235/9075 this is the way to go
  \input{glyphtounicode}
  \pdfgentounicode=1
\fi
\begin{document}

\title{CO 671 Final Project on Semidefinite Programming Integrality Gaps in Quantum Information}
% If Title is too long, use \titlerunning
\titlerunning{SDP Integrality Gaps in Quantum Information}

% Single insitute
\author{Bert Sun}

% If there are too many authors, use \authorrunning
%\authorrunning{First Author et al.}

\institute{University of Waterloo}

%% Multiple insitutes - ALTERNATIVE to the above
% \author{%
%     Firstname Lastname\inst{1} \and
%     Firstname Lastname\inst{2}
% }
%
%If there are too many authors, use \authorrunning
%  \authorrunning{First Author et al.}
%
%  \institute{
%      Insitute 1\\
%      \email{...}\and
%      Insitute 2\\
%      \email{...}
%}

\maketitle

% \begin{abstract}
% \lipsum[1]

% % \keywords{First keyword \and Second keyword \and Third keyword}
% \end{abstract}


\section{Introduction}
\label{sec:introduction}
Semidefinite Programs (SDP) provide a modelling framework to optimize over positive semidefinite (PSD) matrices which partially characterizes many aspects of quantum information where quantum states, channels, and measurements are all required to be representable as a PSD matrix.
As such, SDP formulations of quantum information theoretic problems have found widespread use in approximating optimal solution values to decide state separability \cite{DPShierarchy} and to the class of commutative strategies to nonlocal games \cite{NPAhierarchy}, along with providing exact algebraic characterizations for antidistinguishability of quantum states \cite{Johnston2025tightbounds}.

In both of the above SDP approximation cases relating to state separability and the set of quantum correlations, no unconditional $\omega(1)$-round integrality gaps were known prior to work in \cite{Harrow_2019}.
This project will review work by Harrow, Nataranjan, and Wu which unconditionally shows the above results independent of the Exponential Time Hypothesis, and discuss implications of their work in quantum information and complexity theory along with recent extensions.

\section{Main Results}
\label{sec:mainresults}
\subsection{Notation and Conventions}
\label{sec:notation}
Throughout, calligraphic letters such as $\mcH, \mcK$ will denote Hilbert spaces.
As is the convention in quantum information, subscripts and occasionally superscripts are used to denote membership.
For example, a pure state belonging to $\mcH_A \otimes \mcH_B$ may be written as $\ket{\psi}_{AB}$.
Additionally, a general quantum state represented by elements of $\Dens(\mcH)$ are trace 1 operators acting on $\mcH$.
In an abuse of notation we write $\rho \in \mcH$ to denote a state $\rho$ belonging to the density matrices over $\mcH$.
In general by identifying each Hilbert space with its dimension, we allow the dimension of $\mcH_A$ to be notated by $d_A$.

A state $\rho_{AB} \in \mcH_A \otimes \mcH_B$ is said to be \emph{product state} if there exist density matrices $\rho_A \in \mcH_A, \rho_B \in \mcH_B$ for which $\rho_{AB} = \rho_A \otimes \rho_B$.
The set of \emph{separable states} is then the convex hull of product states.
In particular:
\[\Sep(d_A, d_B) := \conv(\{\rho \otimes \sigma : \rho \in \mcH_A, \sigma \in \mcH_B\})\]
For an arbitrary Hermitian operator $M$ acting on $\mcH_A \otimes \mcH_B$ with $\norm{M}_{\text{op}} \le 1$, define
\[h_{\Sep(d_A, d_B)}(M) := \max_{\rho\in \Sep(d_A, d_B)} \Tr(M\rho)\]
% Since the optimal value is achieved on an extreme point (as $\Sep(d_A, d_B)$ is compact, convex in finite dimensions) this
Furthermore, we shorthand $\Sep(d, d)$ by $\Sep^2(d)$.

A \emph{quantum channel} refers to a completely positive, trace preserving map.

We begin with a list of theorems stated informally.
\subsection{Informal Statements of Main Results}
\label{sec:informalmain}
\begin{theorem}\label{thm:1}
Any SDP extended formulations of $h_{\Sep^2(d)}(\cdot)$ achieving $1/\poly(d)$ accuracy must have $\ge d^{\tilde{\Omega}(\log d)}$ variables.
\end{theorem}

As a corollary of the above, the paper also unconditionally affirms a version of Watrous' ``no approximate disentangler'' conjecture.
Say a quantum channel $\mcN$ is an approximate disentangler from $D$ to $d\times d$ dimensions if $\Image(\mcN) \approx_\eps \Sep(d, d)$ where $\eps \in O(1/\poly(d))$.
Note that $\eps$-closeness for two compact sets is the same as asking for the Pompeiu-Hausdorff distance (with respect to the 1-Schatten/trace norm)to be at most $\eps$.
\begin{theorem}\label{thm:2}
If $D = \dim(\mcH), d = \dim(\mcK)$ and $\Lambda : \Dens(\mcH) \to \Dens(\mcK\otimes \mcK)$ is an approximate disentangler, then
\[D \ge d^{\tilde{\Omega}(\log d)}\]
\end{theorem}
Note that the above two results hide multiplicative factors of $1/\poly \log\log(d)$ in the $\tilde{\Omega}$.

While the above contributions relate to the DPS hierarchy for approximating the set of separable states, Harrow et al. also give lower bounds for the NPA hierarchy for calculating optimal non-local entangled game values.

Briefly, a non-local game $\mcG = (\mcQ_A, \mcQ_B, \mathcal{O}_A, \mathcal{O}_B, V, \pi)$ consists of questions $\mcQ_A, \mcQ_B$ and answers $\mathcal{O}_A, \mathcal{O}_B$ given to Alice and Bob respectively, with victory conditions given by $V: \mcQ_A \times \mcQ_B \times \mathcal{O}_A \times \mathcal{O}_B \to \{0,1\}$ and probability distribution $\pi$ over the question set $\mcQ_A \times \mcQ_B$. 
Alice and Bob are allowed to decide on a strategy beforehand, thereafter a referee then samples questions following $\pi$ and asks them to Alice and Bob separately who are then no longer allowed to communicate.
The value of a game is then the best probability Alice and Bob have to win under a set of allowable classical or quantum correlations.
The classical value is denoted by $\omega_c$, whereas if Alice and Bob are allowed to share a finite-dimensional state which they perform local measurements on, the tensor product value is denote by $\omega_q$.
Local measurements commute, from which the appropriate generalization is to commuting measurements on a possibly infinite dimensional state, with optimal value denoted by $\omega_{qc}$.

It has been known since work by Bell \cite{PhysicsPhysiqueFizika.1.195} that strategies in which Alice and Bob share an entangled state which they then perform local measurements on can outperform classical strategies.
Further work by Tsirelson \cite{tsirelson1993some} bounds exactly how much better quantum strategies can outperform classical correlations (by a multiplicative factor of the Grothendieck constant relating to the dimension of space in which the quantum strategy lives) but also posed conjectures on whether the set of tensor product correlations was equal to the set of commuting correlations.
Tsirelson's strong conjecture was disproved by Slofstra \cite{Slofstra_2019}, while the weak case known to be equivalent to the Conne's embedding problem \cite{MR2790067} stood until a complexity theoretic approach (in a move which frustrated many operator algebraists) refuted it \cite{ji2021mip}. To my best knowledge (a couple of Google searches) an explicit construction of a non-embeddable tracial von Neumann algebra has yet to be found.

In relation to the above discussion, Harrow et al. also give unconditional lower bounds for the error of the ncSoS hierarchy along with minimal SDP dimensions achieving a desired accuracy:

\begin{theorem}\label{thm:3}
  There exists a sequence of non-local games $\mcG_n$ for which the quantum commuting value of the games $\omega_{qc}(\mcG_n) \le 1 - c/n^2$ for some constant $c$ but the ncSoS hierarchy believes $\omega_{qc}(\mcG_n) = 1$ up to level $m = \Omega(n)$.
\end{theorem}

\begin{theorem}\label{thm:4}
  There exists a sequence of non-local games $\mcG_n$ for which any SDP extended formulation approximating $\omega_{qc}(\mcG_n)$ with error $O(1/n^2)$ has dimension $\ge n^{\log n/\poly \log \log n}$.
\end{theorem}

In order to achieve the above results, Harrow et al. set up a framework to ``reduce'' integrality gap results from one problem to another.
The reduction framework introduced provides a method allowing problems with known integrality gap bounds to be reduced to intermediate problems in smaller steps which may be more amenable to analysis which preserves the low degree solutions to produce tighter bounds.
A more detailed analysis of these ideas will be given in \cref{sec:techniques}.

Using this above reduction framework, Harrow, Nataranjan, and Wu also extend results by Lee, Raghavendra, and Steurer in \cite{lee2014lowerboundssizesemidefinite} from boolean domains to non-boolean domains such as the hypersphere. The LRS paper allows one to take integrality gaps in SoS formulations and generalize them to a larger class of SDP extended formulations.

Additionally, previous unconditional hardness of approximation results \cite{tulsiani2009csp,odonnell2014hardnessrobustgraphisomorphism} matching bounds given by either the Exponential Time Hypothesis or the Unique Games Conjecture operate solely over boolean domains.
The paper produces the first unconditional results for SoS hardness problems over non-boolean domains.

My belief is that this last contribution giving a framework to reduce known unconditional integrality gaps for well studied problems to unconditional integrality gaps other problems is the strongest contribution of the paper, and the previous 4 theorems only demonstrate an application of the approach.
A more detailed criticism will be given later in \cref{sec:criticisms}

\section{Techniques and Proof Ideas}
\label{sec:techniques}

\subsection{The Category of Optimization Problems}
\label{sec:optimizationdef}
We give a rigorous definition to the class of optimization problems considered. 
It should be noted that the original definition provided by Harrow et al. is not of a categorical flavour, but I believe a categorical lens offers a cleaner presentation of the main ideas encapsulating the definition while also providing additional tools and conjectures.

\subsubsection{Objects:}
The objects of the category of optimization problems will of course be a suitable definition of optimization problems.
This leads to a definition which suitably encapsulates the ``size'' of optimization problems as a family.
\begin{definition}\label{def:optprob:obj}
  An object $\mathscr{A}$ in the category of optimization problems is a sequence parameterized by $n \in \En$ of tuples $(\mcP_n^A, \Delta_n^A)$ of which:
  \begin{itemize}
    \item \textbf{Feasible Set}: $\mcP_n^A$ denotes a set of feasible solutions at each size $n$
    \item \textbf{Instances}: $\Delta_n^A$ represents a set of optimization problem instances (\ie objective functions) as maps $\Phi: \mcP_n^A \to [0,1]$
  \end{itemize}
  Associated with every $n, \Phi \in \Delta_n^A$, it is also natural to consider the optimal value of the instance denoted by
  \[\OPT(\Phi) \coloneq \max_{x\in \mcP_n^A} \Phi(x)\]
\end{definition}
This definition encapsulates a very broad definition of optimization problems, and in particular admits an (uncountably) infinite number of characterizations by a reindexing of the sequence which defines such a problem.
To this extent, we consider only ``well-formed'' objects where the sequence is indexed correctly by a size which admits a run-time theoretic interpretation.
For example, in the context of semi-definite programs we may consider each $\mcP_n^{\text{SDP}}$ to be the set of all $n\times n$ PSD matrices.
Note that in general any affine function on the set of $n\times n$ PSD matrices does not have range contained in $[0,1]$, but we can simply consider $[0,1]$ isomorphic to the 2-point compactification of the reals and the instances in the above definition will then just be the pullback of any affine function by this isomorphism ($\arctan$, for example).

Combined with the above observation that the instances having co-domain $[0,1]$ is equivalent to the instances having co-domain of the extended reals, we draw notice to that the above definition is robust.
This is because we may consider any class of optimization instances at size $n$(which may not all have the same feasible region) and define the feasible region at size $n$ to be the union over all such instance feasible regions, and encode infeasibility as having objective value $0$.

The restriction to having co-domain $[0,1]$ is natural, however, when considering the specialization to the class of problems at hand.

\begin{definition}
  A \emph{polynomial} optimization problem is one where each $\mcP_n^A$ is a variety (affine, in the algebraic geometry sense) of $\Ree^n$ given by at $m = m(n)$ polynomial equality constraints.
\end{definition}
A special case of a polynomial optimization problem is:
\begin{definition}
  A \emph{boolean} optimization problem is given by the polynomial constraints $x_i^2 = 1$. As such $\mcP_n^{bool}$ is the hypercube $\{-1,1\}^n$ for every $n$.
\end{definition}
\begin{definition}
  A \emph{constraint satisfaction problem} is a boolean optimization problem where each instance is defined by a collection of \emph{clauses} $\{h_1, ..., h_k\}$ where each $h_i : \{\pm 1\}^n \to \{0,1\}$ is boolean, with objective value counting the normalized number of clauses satisfied for some assignment of variables.
\end{definition}

For the specific class of polynomial optimization problems, we wish to further define specific solutions which will allow us to identify integrality gaps.

\begin{definition}
  A \emph{degree-$d$ pseudo-expectation} $\tilde{\mbE}$ is a linear functional from $\Ree[x]^*$ satisfying:
  \begin{itemize}
    \item \textbf{Normalization:} $\tilde{\mbE}[1] = 1$
    \item \textbf{Degree-$d$ Positivity:} $\tilde{\mbE}[p^2] \ge 0$ for any degree-$d/2$ polynomial $p$.
  \end{itemize}
  Furthermore, say $\tilde{\mbE}$ satisfies the constraints $\{g_i\}$ if $\tilde{\mbE}[g_iq] = 0$ for every $i$ and degree $d-\deg(g_i)$ polynomial $q$.
\end{definition}
SDP duality associated with the SoS formulation then implies that the degree-$d$ SoS relaxation of finding the maximum value of a function $f$ on an affine variety defined by constraints $\{g_i\}$ is given by
\[f_{\max}^d = \max\{\tilde{\mbE}[f] : \tilde{\mbE} \text{ is a degree-$d$ pseudo-expectation satisfying } g_i\}\]
\begin{definition}
  Let $\Phi_n^A$ be an instance of an optimization problem $\mathscr{A}$.
  A \emph{degree-$d$ value-$c$ pseudo-solution} for $\Phi_n^A$ is a degree-$d$ pseudo-expectation $\tilde{\mbE}$ satisfying the constraints defining $\mcP_n^A$ such that $\tilde{\mbE}[\Phi_n^A] \ge c$
\end{definition}
Notice that a degree-$d$ value-$c$ pseudo-solution is feasible in the degree-$d$ SoS relaxation.
Exhibiting such a pseudo-solution then implies that the SoS relaxation believes the optimal value of $\Phi_n^A$ is at least $c$, and if the true optimum is lower then this pseudo-solution exhibits an integrality gap for a SoS approach to SDP relaxations.
This is formalized below:
\begin{definition}
  Let $d, c, s$ be functions of $n$, along with the constraint that $0\le s < c \le 1$. Say a collection $\{\Phi_n^A\}$ exhibits a degree-$d$ value-$(c,s)$ integrality gap for a polynomial optimization problem $\mathscr{A}$ if for some $n_0$:
  \begin{itemize}
    \item $\OPT(\Phi_n^A) \le s(n)$ for all $n \ge n_0$
    \item $\exists$ a degree-$d$ value-$c$ pseudo-solution $\tilde{\mbE}_n$ for $\Phi_n^A$ for all $n\ge n_0$.
  \end{itemize}
\end{definition}

\subsubsection{Morphisms:}
A category would not be complete without the proper morphisms.
To this extent we will define the appropriate morphisms for the category of all optimization problems, then define subcategories which preserve valuable properties to allow us to show the existence of an integrality gap.

\begin{definition}
  A morphism (reduction) $R : \mathscr{A} \to \mathscr{B}$ in the category of optimization problems is a collection of maps which identifies sizes and instances of problems. In particular, $R$ consists of:
  \begin{itemize}
    \item $m : \En \to \En$ which maps problems of size $n$ in $\mathscr{A}$ to problems of size $m = m(n)$ in $\mathscr{B}$
    \item $\iota_n: \Delta_n^A \to \Delta_m^A$ mapping every instance of a size $n$ problem in $\mathscr{A}$ to a problem in $\mathscr{B}$ of the appropriate size $m = m(n)$.
  \end{itemize}
  Under a standard abuse of notation, given a reduction from $\mathscr{A}$ to $\mathscr{B}$ we refer to the image of an instance $\Phi \in \Delta_n^A$ under the appropriate map by 
  \[R(\Phi) \coloneq \iota_n(\Phi) \in \Delta_{m(n)}^B\]
  When talking about a reduction and $n$ is fixed, allow $m$ to denote $m(n)$.
\end{definition}
It is clear by definition that our morphisms are transitive.

We can then categorically justify our ``well-formed'' notion above by considering its skeleton category (where we quotient out isomorphism classes of objects) and choosing the distinguished representative object of each isomorphism class to be the representative in which the sequence indexing correctly represents a complexity-theoretic notion of problem size.
Since we are working with sets our category is small and the skeleton is well-defined.

By considering a category to be equivalent to its skeleton, from here onwards when we refer to the category of optimization problems we mean the skeleton category of optimization problems as defined by the objects and morphisms above unless stated otherwise.

\subsubsection{Important Subcategories}
We will define these subcategories as subcategories of the original (non-skeletal) category.
We do not show that the isomorphisms are indeed present in the subcategories which allows them to be well defined in the quotient skeleton category.
It is furthermore also possible that the complexity notions each of the subcategories capture is lost when factoring through the equivalence of categories to the skeleton, but I believe it should still be true.

\begin{definition}
  Given $s, t : \En \to [0,1]$, say a reduction is $(s, t)$\emph{-approximate} if:
  \[\OPT(\Phi_n^A) \le s(n) \imps \OPT(R(\Phi_n^A)) \le t(m)\]
\end{definition}
\begin{definition}
  Say a reduction is \emph{embedding} if there exists a family of maps $E_n : \mcP_n^A \to \mcP_m^B$ such that for any instance $\Phi_n^A$ and $x \in \mcP_n^A$:
  \[\Phi_n^A(x) = R(\Phi_n^A)[E_n(x)]\]
\end{definition}
\begin{definition}
  Say a reduction is $(d^A, c^A, d^B, c^B)$ \emph{pseudo-solution preserving} if for any instance $\Phi_n^A$ for which a degree-$d_n^A$ value-$c_n^A$ pseudo-solution exists, then there exists a degree-$d_m^B$ value $c_m^B$ pseudo-solution to $R(\Phi_n^A)$. Here $d^A, c^A, d^B, c^B$ are functions of $n$, with $d_n^A \coloneq d^A(n)$ and $d_m^B \coloneq d^B(m)$, similarly for $c$.
\end{definition}
\begin{proposition}
  The above approximate, embedding, and pseudo-solution preserving properties are transitive and thus define a subcategory.
\end{proposition}
The value of producing these definitions is in their interpretation: approximate reductions are sound, embedding reductions are complete in a strong sense.
This additional strength of the completeness of the reduction was required to reduce SoS integrality gaps to a larger class of SDP formulations.
Additionally, the last definition provides a method to produce an integrality gap for a problem $\mathscr{B}$ given an appropriate reduction from $\mathscr{A}$ with a known integrality gap:
\begin{proposition}\label{prop:2}
  Let $\mathscr{A}, \mathscr{B}$ be polynomial optimization problems. If $\mathscr{A}$ has a degree-$d^A$ value-$(c^A, s^A)$ integrality gap, and there exists a $(s^A, s^B)$-approximate, $(d^A, c^A, d^B, c^B)$-pseudo-solution preserving reduction $R$ from $\mathscr{A}$ to $\mathscr{B}$, then there exists a degree-$d^B$ value-$(c^B, s^B)$ integrality gap for $\mathscr{B}$.
\end{proposition}
\begin{proof}
  Follows from the definitions by applying $R$ to the integrality gap exhibiting family for $\mathscr{A}$ to produce one for $\mathscr{B}$.
\end{proof}
From the above proposition, it then suffices to produce a sequence of approximate, pseudo-solution preserving reductions from a problem with known integrality gap to the one we wish to answer.
In the case of \cref{thm:1,thm:2} the sequence of reductions is:
\begin{theorem}\label{thm:5}
  There exists a sequence of reductions:
  \[\textsc{3XOR} \imps \textsc{2-out-of-4-SAT-EQ} \imps \textsc{QMA(2)-Honest} \imps h_{\Sep^2(n^{\sqrt{n}})}\]
  Each of which is $(n, 1, \Omega(n), 1)$-pseudo-solution preserving.
  The first is $(1/2+\eps, 1-\delta)$-approximate for some constant $\delta$, and the second is a family of $(1-\delta, \eps)$-approximate for any $\eps$. The third is exact.
\end{theorem}
Where \textsc{2-out-of-4-SAT-EQ} is the boolean satisfiability problem where we ask for every clause to have 4 variables and exactly 2 of the 4 to be true, and \textsc{QMA(2)-Honest} is the probability that an honest QMA(2) prover following a specific protocol accepts an input string.
The exact protocol used in the definition we omit here, but refer to \cite{aaronson2008powerunentanglement,harrow2013testing} for a first $k$-partite definition followed by a reduction from $k$-partite provers to bipartite provers.

Both of the first two reductions are a technical rework of previously known results from \cite{aaronson2008powerunentanglement,harrow2013testing} just reframed in the context of the reduction framework posed.

Next, to extend the above SoS hardness results to extended SDP formulations, it is shown that:
\begin{lemma}\label{lemma:1}
  The last reduction in \cref{thm:5} is additionally embedding.
\end{lemma}
Whence using the pattern matrix analysis techniques of \cite{lee2014lowerboundssizesemidefinite} to bound the dimension of approximate SDP extended formulations for \textsc{QMA(2)-Honest} combined with \cref{lemma:1} shows \cref{thm:1}.

Next, to show \cref{thm:2} it is shown that:
\begin{lemma}\label{lemma:2}
  Let $d = \dim(\mcK)$. An $(\eps, \delta)$ approximate disentangler $\Lambda : \Dens(\mcH) \to \Dens{\mcK \otimes \mcK}$ with $\eps + \delta < 1/\poly(d)$ induces an extended SDP formulation to $h_{\Sep^2(d)}$ of size $\dim(\mcH)$.
\end{lemma}
Then \cref{thm:1} combined with this above lemma gives lower bounds on the dimension of $\mcH$ necessary for an approximate disentangler to exist.

It should be noted that ETH-based hardness results do not require $\Omega$ in the dimension and have $\eps + \delta < O(1)$. These costs are incurred in the LRS reduction of SoS hardness to extended SDP formulation hardness.

The proofs for \cref{thm:3,thm:4} follow a similar pattern, except using the chain of reductions:
\begin{lemma}\label{lemma:3}
  There exists a sequence of reductions:
  \[\textsc{3XOR} \imps \omega_{\textsc{honest classical}} \imps \omega_{\text{entangled}}\]
  The second of which is embedding.
\end{lemma}
The above follows work in \cite{ito2008oracularizationtwoproveroneroundinteractive} with careful analysis to show that it is additionally embedding in order to once again apply LRS techniques to $\omega_{\textsc{honest classical}}$.

\section{Potential Applications}
\label{sec:applications}
I believe that the most interesting of the contributions provided is actually in the formulation of the optimization problem reduction framework.
In this report I have reformulated their results in a categorical flavour, and as such would like to ask similarly inspired questions.

\begin{conjecture}
Is \textsc{3XOR} initial in the subcategory of SoS approximation-hard problems?
\end{conjecture}
Where initial refers to the existence of a morphism to every object in the category.
We ask this because it seems that \textsc{3XOR} reduces to many SoS approximation-hard problems.
Alternatively,
\begin{conjecture}
Does there exist an initial object in the subcategory of SoS approximation-hard problems?
\end{conjecture}
If there were to exist such an initial object it would seemingly suggest that any SoS approximation-hard problem must be capable of modelling problems from this initial object.
In particular, this would suggest a certain structure that any SoS approximation-hard problem must encapsulate.
It would be interesting if this were to be the case but it seems much more reasonable that there are differing SoS-hard structures.

In order to produce tight SoS-degree and error bounds, the LRS procedure was applied to intermediate steps.
\ie \textsc{QMA(2)-Honest} and $\omega_{\textsc{classical honest}}$ in \cref{thm:1,thm:3}.
It is unclear to me why it is neccessary to extract no-go results from intermediate problems.
At the very least, \textsc{3XOR} was initial for all discussed problems in this paper.
An LRS approach for a no-go result to \textsc{3XOR} would provide relevant bounds for every reduction without having to do each individually.
Weakness in the results may then be indicative of unexploited structure in reductions which may lead to stronger results.
It would be interesting to do a deeper analysis to see where such issues may arise.

It is worth noting that the LRS approach at least for \cref{thm:2} provides bounds which are slightly weaker than ETH-assumption based hardness results.
This gap may be due to either falseness of the ETH, or a suggestion of improvements to the LRS technique.
Additionally, with such improvements to the LRS technique it may be the case that its application to \textsc{3XOR} provides a wide class of no-go approximation results for extended SDP formulations if \textsc{3XOR} were to be initial.

\begin{conjecture}
Does there exist a final object in the subcategory of SoS approxi-mation-hard problems?
\end{conjecture}
This above is equivalent to a completeness property.
It would also be interesting to investigate the intersection of these SoS approximation-hard problems with MAX-SNP problems introduced by \cite{PAPADIMITRIOU1991425}.
It is noteworthy that there is a reduction presented which reduces \textsc{3XOR} to asking if a graph is 3-colourable, which is we may ask as a MAX-SNP problem.
This is further reduced to a question about $h_{\Sep^{O(\sqrt{n})}(n)}$ which implements the Chen-Drucker \cite{chen2010shortmultiproverquantumproofs} QMA protocol to answer MAX-3SAT with completeness $1-\exp(-\Omega(n))$ and soundness $1-\Omega(1)$.
It is noteworthy that MAX-3SAT is MAX SNP-complete.
Following these ideas, one can also embed any boolean CSP as a tripartite non-local game with a pseudo-telepathic strategy if and only if the CSP is satisfiable \cite{preda2011non}.
This should not be too surprising as boolean CSP is only NP-hard whereas the decision problem of whether a non-local game has entangled value of 1 or less than $1/2$ is undecidable \cite{ji2021mip}.

Additionally, a quantum counterpart to the UGC has been proposed \cite{mousavi2024quantumuniquegamesconjecture} which extends NP-hard problems to quantum undecidable counterparts.
There seems to be areas of overlap between these ideas and may be worthwhile to investigate.

\begin{conjecture}
Is the LRS procedure functorial?
\end{conjecture}
Where a functor is a morphism in the 2-category where the objects are the morphisms originally considered.
We ask this because the LRS procedure seemingly provides a method which intakes an embedding morphism from an SoS-hard problem to a second problem in question and produces a morphism from the extended SDP formulations to the second problem.
The original LRS construction seems to operate only on the subcategory of constraint satisfaction problems, but this paper by Harrow et al. extends their construction to two particular instances over the hypersphere.
An categorical approach to extending LRS results may lead to a functorial approach in which one can conclude extended SDP formulation hardness from any SoS approach hardness.

Furthermore, a bulk of the work presented in this paper was a rework of previously known results in order to fit them into this framework (see \cref{sec:criticisms}). 
With wider acceptance of this framework it would seem that a lot of approximation results can be condensed into showing the existence of a family of approximate reductions.

Finally, it is noted that solving $h_{\Sep}$ equivalent to solving the $2\to 4$ norm of a matrix \cite{Barak_2012}, defined as:
\[\norm{A}_{2\to 4} \coloneq \sup_v \{\norm{Av}_q/\norm{v}_2\}\]
Which is a particular case of the $2\to q$ norm of a matrix.
It turns out that good approximations to the $2\to q$ for norm of a matrix for $q \ge 4$ would refute the Small-Set Expansion Conjecture, which is a relaxation of the UGC \cite{Barak_2012}.
This paper rules out SDP approaches to $2\to 4$ norms and perhaps may be generalized for arbitrary $q \ge 4$ unconditionally, where previous known approaches only gave ETH-based bounds.

\section{Connections to CO671}
We discuss a few connections to SDP approximations and the Unique Games Conjecture covered in CO 671:
\subsection{SDP Approximations}
The bulk of the paper essentially discusses unconditional bounds for the approximation capacity of SDPs in the context of quantum information.
Though not the focus point of this particular paper, it makes heavy use of prior results relating to SDP relaxations to solve state separability problems and SDP approximations to quantum commuting value of a non-local game.
The Lov\'asz-Schrijver (LS) hierarchy was studied in class, but admits refinements by the Lasserre (SoS) hierarchy \cite{laurent2003comparison}.

Since the Lasserre refinements are contained in the Lova\'sz-Schrijver refinements, the results obtained on the SoS techniques apply to the LS lift as well.
If one were strictly curious about the performance of the LS lifts it may even be possible to produce larger integrality gaps, along with requiring a lower degree/level of lift.

In fact, the LRS technique applied to particular boolean CSP problems makes use of the non-negative rank, $\rank_+$ as defined in the lecture series on extension complexity, in order to lower bound the dimension of extended formulations and thus should be viewed as lower bounds on the dimension of lifted representations of boolean CSP polytopes which generalizes Yannakakis' work \cite{yannakakis1988expressing}.
Additional work presented in class by Fiorini, Massar, Pokutta, Tiwang, and de Wolf \cite{fiorini2015exponential} on generalizing TSP, STAB, and CUT polytopes similarly fall under this larger umbrella of boolean CSP problems.

It should be noted however, that the LRS technique only provides a \emph{sub-exponential} lower-bound on the extension complexity, unlike work by Rothvo\ss\, giving an exponential bound \cite{rothvoss2013some} on some 0,1-polytopes.

\subsection{Unique Games Conjecture}
It was mentioned above in \cref{sec:applications} that deciding the separability of a given density matrix is closely related with the SSE conjecture, which in turn is a relaxation of the UGC.
This paper gives unconditional hardness of approximation results for the $2\to 4$ norm of a matrix, but it remains to be seen if this can be generalized to arbitrary $q \ge 4$.
If such results would hold then this would give strong unconditional evidence towards the SSE conjecture.
It is not clear however that SDP approximations necessarily provide the best approach towards such norm approximations, however, so further work still must be done.

\subsection{Convex Algebraic Geometry}
Though not a staple of the paper either, the entirety of the work depends on the algebraicity of the underlying feasible set being representable as an affine variety.
The true connection likely lies in the weeds of the LRS proof.

\section{Criticisms}
\label{sec:criticisms}
The largest criticism I have for this work is the presentation of the optimization problem framework.
Many definitions are made and explanations are made for one might care for these definitions (see \cref{prop:2}) after which the language is essentially never used again.
A particular nitpick is in \cref{thm:5} in which I had to reverse engineer values to put their proof into the language of the framework that is presented the section before.
In the original language, each proof only exhibits an integrality gap for each problem in the chain of reductions but each reduction indeed encapsulates a $*$-approximate, $*$-pseudo-solution preserving reduction from which the integrality gap of the next problem in the chain is deduced from.

It is unclear to me why the framework is going to be introduced if the remainder of the work is not going to be framed as so.
Specifically, each reduction produces a proposition stating that ``there exists a degree-$\Omega(n)$ value-$(1,\eps)$ integrality gap'' rather than a statement of existence of the appropriate category of reduction.
The entirety of the definitions are practically ditched in favour of the language of preexisting reduction proofs.
I might even go as far as to say that the work may not have gotten the recognition due to how verbose and difficult to parse.

There is no criticism about the ideas, however, as a nice reframing of their presentation provides some interesting questions in \cref{sec:applications}.
Reading the paper as it is feels like searching for a needle in a haystack for the actually interesting contributions.
In particular, ``slight tweaks'' to previously known reductions which allow one to nicely show a degree-preserving property might better belong in an appendix in order to properly highlight the novel work done with respect to a novel technique which allows LRS ideas to be applied in non-boolean domains.

% \section{Conclusion and Outlook}
% \label{sec:outlook}
% \lipsum[1-2]

% \subsubsection*{Acknowledgments}

% Identification of funding sources and other support, and thanks to individuals and groups that assisted in the research and the preparation of the work should be included in an acknowledgment section, which is placed just before the reference section in your document

%%% ===============================================================================
%%% Bibliography
%%% ===============================================================================

% In the bibliography, use \texttt{\textbackslash textsuperscript} for \enquote{st}, \enquote{nd}, \ldots:
% E.g., \enquote{The 2\textsuperscript{nd} conference on examples}.
% When you use \href{https://www.jabref.org}{JabRef}, you can use the clean up command to achieve that.
% See \url{https://help.jabref.org/en/CleanupEntries} for an overview of the cleanup functionality.

\renewcommand{\bibsection}{\section*{References}} % requried for natbib to have "References" printed and as section*, not chapter*
% Use natbib compatbile splncs04nat style.
% It does provide all features of splncs04.bst, but is developed in a clean way.
% Source: https://github.com/tpavlic/splncs04nat
\bibliographystyle{splncs04nat}
\begingroup
  \microtypecontext{expansion=sloppy}
  \small % ensure correct font size for the bibliography
  \bibliography{paper}
\endgroup

% Enfore empty line after bibliography
% \ \\
% %
% \noindent
% All links were last followed on October 5, 2020.

%%% ===============================================================================
%\appendix
%\addcontentsline{toc}{chapter}{APPENDICES}

%\listoffigures
%\listoftables
%%% ===============================================================================

%%% ===============================================================================
%\section{My first appendix}\label{sec:appendix1}
%%% ===============================================================================
\end{document}
